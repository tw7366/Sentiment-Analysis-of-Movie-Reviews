{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis of Movie Reviews.ipynb",
      "provenance": [],
      "mount_file_id": "19WntYl02GGdh6VjuUNEe3RwmeagqM4eW",
      "authorship_tag": "ABX9TyNMVxjTC2LXUy9s4Vr83IGP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tw7366/Sentiment-Analysis-of-Movie-Reviews/blob/master/Sentiment%20Analysis%20of%20Movie%20Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rbam0TjVrXs"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMMcVpT8CErJ",
        "outputId": "e16b3c6a-240f-4985-9510-db940e85a103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "reviews_df=pd.read_csv('drive/My Drive/IMDB Dataset.csv')\n",
        "reviews = np.array(reviews_df['review'])\n",
        "sentiment = np.array(reviews_df['sentiment'])\n",
        "print(reviews[:3])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"\n",
            " 'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'\n",
            " 'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I\\'d laughed at one of Woody\\'s comedies in years (dare I say a decade?). While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WfnKf91VxkJ"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import WordNetLemmatizer\n",
        "\n",
        "stops = set(stopwords.words(\"english\"))\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_review(review_list):\n",
        "    \"\"\"\n",
        "    param: a list of string\n",
        "    return: a list of string\n",
        "    preprocess reviews by changing all alphabets to lowercase, removing punctuations, and cleaning html leftover code\n",
        "    \"\"\"\n",
        "    for i, review in enumerate(review_list):\n",
        "        review = review.replace('<br /><br />', ' ')\n",
        "        review = review.lower()\n",
        "        review = re.sub(r\"[^A-Za-z0-9' ]+\", '', review)\n",
        "        review = review.replace('  ', ' ')\n",
        "        review_list[i] = review\n",
        "    return review_list\n",
        "\n",
        "\n",
        "def remove_stops(string_list):\n",
        "  \"\"\"\n",
        "  param: a list of strings\n",
        "  return: a list of strings without stopwords\n",
        "  remove all stopwords from a list\n",
        "  \"\"\"\n",
        "  # tokenized_list = []\n",
        "  # final_list = []\n",
        "\n",
        "  # tokenize words\n",
        "  for i, string in enumerate(string_list):\n",
        "    pre_filtered = word_tokenize(string)\n",
        "    filtered = [lemma.lemmatize(word, pos = \"v\") for word in pre_filtered]\n",
        "    filtered = [lemma.lemmatize(word, pos = \"n\") for word in filtered]\n",
        "    filtered = [word for word in filtered if not word in stops]\n",
        "    filtered_string = ' '.join(filtered)\n",
        "    string_list[i] = filtered_string \n",
        "  return string_list\n",
        "\n",
        "\n",
        "preprocessed_reviews = preprocess_review(reviews)\n",
        "preprocessed_reviews = remove_stops(preprocessed_reviews)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGlwUksABoH6",
        "outputId": "451cf2ef-3e57-4ac5-ce81-29f0c01bbdf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "# to divide train & test sets\n",
        "test_sample_size = int(0.1*len(preprocessed_reviews))  # 10% of data as the validation set\n",
        "\n",
        "# for sentiment\n",
        "sentiment = [1 if x=='positive' else 0 for x in sentiment]\n",
        "\n",
        "# separate data to train & test sets\n",
        "X_test, X_train = (np.array(preprocessed_reviews[:test_sample_size]), \n",
        "                   np.array(preprocessed_reviews[test_sample_size:])\n",
        ")\n",
        "\n",
        "y_test, y_train = (np.array(sentiment[:test_sample_size]), \n",
        "                   np.array(sentiment[test_sample_size:])\n",
        ")\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(oov_token='<OOV>')  # for the unknown words\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "vocab_count = len(tokenizer.word_index) + 1  # +1 is for padding\n",
        "\n",
        "# create padded sequences\n",
        "training_sequences = tokenizer.texts_to_sequences(X_train)  # tokenizer.word_index to see indexes\n",
        "training_padded = pad_sequences(training_sequences, padding='post')  # pad sequences with 0s\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(X_test)  # tokenizer.word_index to see indexes\n",
        "testing_padded = pad_sequences(testing_sequences, padding='post')  # pad sequences with 0s\n",
        "\n",
        "input_length = len(testing_padded[0])  # length of all sequences\n",
        "\n",
        "\n",
        "# build a model\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Embedding(input_dim=vocab_count,\n",
        "                                 output_dim=4,\n",
        "                                 input_length=input_length,\n",
        "                                 mask_zero = True)\n",
        ")\n",
        "model.add(keras.layers.GlobalAveragePooling1D())  # find the average of vectors to get sentiment\n",
        "model.add(keras.layers.Dense(64, activation='relu'))  # hidden layer\n",
        "model.add(keras.layers.Dense(16, activation='relu'))  # hidden layer\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))  # output layer\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 947, 4)            547012    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                320       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 548,389\n",
            "Trainable params: 548,389\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60n8u11yDx7u",
        "outputId": "5489bcfd-a488-4795-b99d-cbd54e4c7366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "model.fit(training_padded, y_train, epochs=5, batch_size=512,\n",
        "          validation_data=(testing_padded, y_test)\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 947) for input Tensor(\"embedding_input:0\", shape=(None, 947), dtype=float32), but it was called on an input with incompatible shape (None, 1458).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 947) for input Tensor(\"embedding_input:0\", shape=(None, 947), dtype=float32), but it was called on an input with incompatible shape (None, 1458).\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 0.6748 - accuracy: 0.6854 - val_loss: 0.6177 - val_accuracy: 0.8174\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 0.4624 - accuracy: 0.8567 - val_loss: 0.3284 - val_accuracy: 0.8830\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 0.2577 - accuracy: 0.9057 - val_loss: 0.2577 - val_accuracy: 0.8998\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 0.1906 - accuracy: 0.9304 - val_loss: 0.2419 - val_accuracy: 0.9056\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 2s 25ms/step - loss: 0.1507 - accuracy: 0.9466 - val_loss: 0.2430 - val_accuracy: 0.9058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f22fbb376d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71wlIbmAvYNi",
        "outputId": "43cf1603-2eed-4a66-fdd1-fae4d9d301f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "index_list = []\n",
        "predictions = model.predict(training_padded)\n",
        "predictions = ['negative' if x <= 0.5 else 'positive' for x in predictions]\n",
        "y_test = ['negative' if x <= 0.5 else 'positive' for x in y_test]\n",
        "for i, (prediction, truth) in enumerate(zip(predictions, y_test)):\n",
        "    if prediction != truth:\n",
        "        index_list.append(i)\n",
        "\n",
        "print(f'The model has predicted {len(index_list)} wrong of {len(predictions)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 947) for input Tensor(\"embedding_input:0\", shape=(None, 947), dtype=float32), but it was called on an input with incompatible shape (None, 1458).\n",
            "The model has predicted 2498 wrong of 45000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ll59I04vl0M",
        "outputId": "25414e09-a17d-48e3-e46a-94289acbab46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "for i, item in enumerate(index_list):\n",
        "    if i <= 5:\n",
        "        print(X_test[item])\n",
        "        print(f'Prediction: {predictions[item]}')\n",
        "        print(f'Sentiment: {y_test[item]}')\n",
        "        print('============================')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "one reviewer mention watch 1 oz episode 'll hook right exactly happen first thing strike oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use word call oz nickname give oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home manyaryans muslim gangsta latino christian italian irish moreso scuffle death star dodgy deal shady agreement never far away would say main appeal show due fact go show would n't dare forget pretty picture paint mainstream audience forget charm forget romanceoz n't mess around first episode ever saw strike nasty surreal could n't say ready watch develop taste oz get accustom high level graphic violence violence injustice crook guard 'll sell nickel inmate 'll kill order get away well mannered middle class inmate turn prison bitch due lack street skill prison experience watch oz may become comfortable uncomfortable viewingthats get touch darker side\n",
            "Prediction: negative\n",
            "Sentiment: positive\n",
            "============================\n",
            "probably alltime favorite movie story selflessness sacrifice dedication noble cause 's preachy bore never get old despite see 15 time last 25 year paul lukas ' performance bring tear eye bette davis one truly sympathetic role delight kid grandma say like dressedup midget child make fun watch mother 's slow awaken 's happen world roof believable startle dozen thumb 'd movie\n",
            "Prediction: negative\n",
            "Sentiment: positive\n",
            "============================\n",
            "sure would like see resurrection date seahunt series tech today would bring back kid excitement mei grow black white tv seahunt gunsmoke hero 's every weekyou vote comeback new sea huntwe need change pace tv would work world water adventureoh way thank outlet like view many viewpoint tv many moviesso ole way believe 've get wan na saywould nice read plus point sea huntif rhyme would 10 line would let submitor leave doubt quitif must go let\n",
            "Prediction: negative\n",
            "Sentiment: positive\n",
            "============================\n",
            "show amaze fresh innovative idea 70 's first air first 7 8 year brilliant thing drop 1990 show really funny anymore 's continue decline complete waste time today 's truly disgraceful far show fall write painfully bad performance almost bad mildly entertain respite guesthosts show probably would n't still air find hard believe creator handselected original cast also choose band hack follow one recognize brilliance see fit replace mediocrity felt must give 2 star respect original cast make show huge success show awful ca n't believe 's still air\n",
            "Prediction: positive\n",
            "Sentiment: negative\n",
            "============================\n",
            "saw movie 12 come recall scariest scene big bird eat men dangle helplessly parachute right air horror horror young kid go cheesy b film saturday afternoon still tire formula monster type movie usually include hero beautiful woman might daughter professor happy resolution monster die end n't care much romantic angle 12 year old predictable plot love unintentional humor year later saw psycho come love star janet leigh bump early film sit take notice point since screenwriter make story make scary possible wellworn formula rule\n",
            "Prediction: positive\n",
            "Sentiment: negative\n",
            "============================\n",
            "im big fan boll 's work many enjoy movie postal maybe im one boll apparently buy right use far cry long ago even game even finsished people enjoy kill mercs infiltrate secret research lab locate tropical island warn far cry something mr boll scheme together along legion schmuck feel loneley set mr boll invite three countryman play player go name til schweiger udo kier ralf moeller three name actually make self pretty big movie biz tale go like jack carver play til schweiger yes carver german hail bratwurst eat dude however find tils act movie pretty badass people complain 's really stay true whole carver agenda saw carver first person perspective n't really know look like kick however storyline film beyond demented see evil mad scientist dr krieger play udo kier make geneticallymutatedsoldiers gm call perform topsecret research island remind spoiler vancouver reason thats right palm tree instead get nice rich lumberjackwoods n't even go far start cry mehehe go wan na stay true boll shenanigan go see movie disappoint deliver true boll experience mean suck thing worth mention would imply boll good work area film nice boat fight scene whole cromedalbino gm squad enter scene everything make laugh movie far cry reek scheisse 's poop simpleton far wan na take wiff go ahead btw carver get annoy sidekick make wan na shoot first three minute 's screen\n",
            "Prediction: positive\n",
            "Sentiment: negative\n",
            "============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCDFvLkkvqIU"
      },
      "source": [
        "The model made good assumptions for most of them, but it got easily confused by words like 'good', 'bad', 'well', etc. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbnWtDS4D93N"
      },
      "source": [
        "LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5o3OGe0P0rT"
      },
      "source": [
        "y_test = [0 if x == 'negative' else 1 for x in y_test]\n",
        "\n",
        "# the model takes numpy arrays as inputs\n",
        "y_test = np.asarray(y_test).astype(np.float32)\n",
        "y_train = np.asarray(y_train).astype(np.float32)\n",
        "\n",
        "for i, (train_item, test_item) in enumerate(zip(training_padded, testing_padded)):\n",
        "    training_padded[i] = np.asarray(train_item).astype(np.float32)\n",
        "    testing_padded[i] = np.asarray(test_item).astype(np.float32)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrAS0p3bEBZT",
        "outputId": "77143b0a-4908-44ae-b4fe-901925394c80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "from tensorflow.keras.layers import SpatialDropout1D, Embedding, LSTM, Bidirectional, Dense\n",
        "\n",
        "new_model = keras.models.Sequential()\n",
        "new_model.add(Embedding(input_dim=vocab_count,\n",
        "                        output_dim=4,\n",
        "                        input_length=input_length))\n",
        "new_model.add(Bidirectional(tf.keras.layers.LSTM(16, dropout=0.2)))\n",
        "new_model.add(Dense(16, activation='relu'))\n",
        "new_model.add(Dense(1, activation='sigmoid'))\n",
        "new_model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "print(new_model.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 947, 4)            547012    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 32)                2688      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 550,245\n",
            "Trainable params: 550,245\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QZJLU7hEH8Q",
        "outputId": "750f982c-f519-42ee-8e14-4df32491714c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "new_model.fit(training_padded, y_train, epochs=5, batch_size=512,\n",
        "              validation_data=(testing_padded, y_test)\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 947) for input Tensor(\"embedding_1_input:0\", shape=(None, 947), dtype=float32), but it was called on an input with incompatible shape (None, 1458).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 947) for input Tensor(\"embedding_1_input:0\", shape=(None, 947), dtype=float32), but it was called on an input with incompatible shape (None, 1458).\n",
            "88/88 [==============================] - 13s 153ms/step - loss: 0.6449 - accuracy: 0.6418 - val_loss: 0.4477 - val_accuracy: 0.8022\n",
            "Epoch 2/5\n",
            "88/88 [==============================] - 13s 149ms/step - loss: 0.3356 - accuracy: 0.8669 - val_loss: 0.2662 - val_accuracy: 0.8988\n",
            "Epoch 3/5\n",
            "88/88 [==============================] - 13s 148ms/step - loss: 0.2073 - accuracy: 0.9228 - val_loss: 0.2419 - val_accuracy: 0.9024\n",
            "Epoch 4/5\n",
            "88/88 [==============================] - 13s 149ms/step - loss: 0.1553 - accuracy: 0.9454 - val_loss: 0.2503 - val_accuracy: 0.9020\n",
            "Epoch 5/5\n",
            "88/88 [==============================] - 13s 149ms/step - loss: 0.1218 - accuracy: 0.9573 - val_loss: 0.2651 - val_accuracy: 0.8990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f22f0597f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRjoDDEaFQZI",
        "outputId": "69971e7f-1727-46d8-9492-5a20676addc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "new_index_list = []\n",
        "new_predictions = new_model.predict(testing_padded)\n",
        "new_predictions = ['negative' if x <= 0.5 else 'positive' for x in new_predictions]\n",
        "y_test = ['negative' if x <= 0.5 else 'positive' for x in y_test]\n",
        "for i, (prediction, truth) in enumerate(zip(new_predictions, y_test)):\n",
        "    if prediction != truth:\n",
        "        new_index_list.append(i)\n",
        "\n",
        "print(f'The model has predicted {len(new_index_list)} wrong of {len(new_predictions)}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has predicted 505 wrong of 5000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}